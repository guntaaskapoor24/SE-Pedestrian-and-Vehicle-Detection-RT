{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sYd5FWGthM0K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle"
      ],
      "metadata": {
        "id": "KdGna7h7hR9E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“¦ Installing Roboflow...\")\n",
        "!pip install -q roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UytNwosIhVKe",
        "outputId": "fccfcda7-dd06-44a1-b351-ac5782043523"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ Installing Roboflow...\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass(\"Paste your Roboflow API key here: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO7Z0msshsU3",
        "outputId": "32005895-20e2-4f0c-f4c0-0c5730e950a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your Roboflow API key here: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“¥ Downloading BDD100K from Roboflow...\")\n",
        "print(\"âš¡ This will be in YOLO format - no conversion needed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dbUyI2qk_MY",
        "outputId": "27d2b558-77f3-435e-901f-ffd64e87873f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¥ Downloading BDD100K from Roboflow...\n",
            "âš¡ This will be in YOLO format - no conversion needed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "# Initialize Roboflow\n",
        "rf = Roboflow(api_key=api_key)"
      ],
      "metadata": {
        "id": "kijJYwdTlFw5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Access Pedro Azevedo's BDD100K dataset (9900 images, cars + pedestrians)\n",
        "    project = rf.workspace(\"pedro-azevedo-3c9ol\").project(\"bdd100k-3zgda\")\n",
        "\n",
        "    print(\"âœ“ Found BDD100K dataset!\")\n",
        "    print(f\"  Workspace: pedro-azevedo-3c9ol\")\n",
        "    print(f\"  Project: bdd100k-3zgda\")\n",
        "    print(f\"  Images: ~9,900 (cars + pedestrians)\")\n",
        "\n",
        "    # Get the latest version (v5)\n",
        "    version = project.version(5)\n",
        "\n",
        "    # Download in YOLOv9 format\n",
        "    print(\"\\nğŸ“¥ Downloading dataset...\")\n",
        "    print(\"   Format: YOLOv9\")\n",
        "    print(\"   Location: /content/bdd100k\")\n",
        "\n",
        "    dataset = version.download(\"yolov9\", location=\"/content/bdd100k\")\n",
        "\n",
        "    print(\"\\nâœ“ Download complete!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâš ï¸  Could not access that specific dataset.\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"\\nğŸ“ Alternative: Search for BDD100K on Roboflow Universe\")\n",
        "    print(\"   Go to: https://universe.roboflow.com/\")\n",
        "    print(\"   Search: 'BDD100K' or 'Berkeley Deep Drive'\")\n",
        "    print(\"   Choose a dataset and use its workspace/project names\")\n",
        "    print(\"\\n   Then update the code:\")\n",
        "    print(\"   project = rf.workspace('WORKSPACE_NAME').project('PROJECT_NAME')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhOZVh_UlKTV",
        "outputId": "7e3290b5-4f2b-4054-fd67-d25c67b6b8a1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "âœ“ Found BDD100K dataset!\n",
            "  Workspace: pedro-azevedo-3c9ol\n",
            "  Project: bdd100k-3zgda\n",
            "  Images: ~9,900 (cars + pedestrians)\n",
            "\n",
            "ğŸ“¥ Downloading dataset...\n",
            "   Format: YOLOv9\n",
            "   Location: /content/bdd100k\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/bdd100k to yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419570/419570 [00:24<00:00, 17158.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/bdd100k in yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18570/18570 [00:02<00:00, 7636.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Download complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(dataset_path):\n",
        "    print(f\"\\nğŸ“ Dataset location: {dataset_path}\")\n",
        "\n",
        "    # Show structure\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        level = root.replace(dataset_path, '').count(os.sep)\n",
        "        indent = '  ' * level\n",
        "        print(f'{indent}ğŸ“ {os.path.basename(root)}/')\n",
        "        subindent = '  ' * (level + 1)\n",
        "        for file in files[:5]:\n",
        "            print(f'{subindent}ğŸ“„ {file}')\n",
        "        if len(files) > 5:\n",
        "            print(f'{subindent}... and {len(files)-5} more files')\n",
        "        if level > 2:\n",
        "            break\n",
        "\n",
        "    # Find data.yaml\n",
        "    yaml_files = []\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.yaml') or file.endswith('.yml'):\n",
        "                yaml_files.append(os.path.join(root, file))\n",
        "\n",
        "    if yaml_files:\n",
        "        print(f\"\\nâœ“ Found config file: {yaml_files[0]}\")\n",
        "        print(\"\\nConfig contents:\")\n",
        "        with open(yaml_files[0], 'r') as f:\n",
        "            print(f.read())\n",
        "\n",
        "        yaml_path = yaml_files[0]\n",
        "    else:\n",
        "        print(\"\\nâš ï¸  No YAML config found\")\n",
        "        yaml_path = None\n",
        "\n",
        "    # Count images\n",
        "    train_imgs = len([f for f in os.listdir(f\"{dataset_path}/train/images\") if f.endswith(('.jpg', '.png'))]) if os.path.exists(f\"{dataset_path}/train/images\") else 0\n",
        "    val_imgs = len([f for f in os.listdir(f\"{dataset_path}/valid/images\") if f.endswith(('.jpg', '.png'))]) if os.path.exists(f\"{dataset_path}/valid/images\") else 0\n",
        "\n",
        "    print(f\"\\nğŸ“Š Dataset Statistics:\")\n",
        "    print(f\"  Training images: {train_imgs}\")\n",
        "    print(f\"  Validation images: {val_imgs}\")\n",
        "    print(f\"  Total: {train_imgs + val_imgs}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nâš ï¸  Dataset not found at {dataset_path}\")\n",
        "    yaml_path = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VrT63kzlRbH",
        "outputId": "302827fe-9fbe-441f-cff6-002f68394a7c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“ Dataset location: /content/bdd100k\n",
            "ğŸ“ bdd100k/\n",
            "  ğŸ“„ README.roboflow.txt\n",
            "  ğŸ“„ README.dataset.txt\n",
            "  ğŸ“„ data.yaml\n",
            "  ğŸ“ valid/\n",
            "    ğŸ“ images/\n",
            "      ğŸ“„ c6580b8a-368c5647_jpg.rf.ea08a22b0420d30ca234c6e437fda52c.jpg\n",
            "      ğŸ“„ c376fce7-54f5721d_jpg.rf.73dfd9ced4c0219520fe5124116e6c68.jpg\n",
            "      ğŸ“„ b5dd8a5f-ef468c83_jpg.rf.bce953e39cfe60551e26f5b96af4ef6e.jpg\n",
            "      ğŸ“„ c65628b7-78e929a2_jpg.rf.1d06ca6ff57d096a7ff6c38b2ae3dced.jpg\n",
            "      ğŸ“„ c08eacf9-8054501c_jpg.rf.cfed03ba928e50631b651f33e64e8d04.jpg\n",
            "      ... and 2003 more files\n",
            "    ğŸ“ labels/\n",
            "      ğŸ“„ b4301c7b-da5261f0_jpg.rf.20bc5076070624a175393c5d2354813a.txt\n",
            "      ğŸ“„ c91d0862-74c58649_jpg.rf.0572ae7df0c16dd5155a815043ab115c.txt\n",
            "      ğŸ“„ c01c4d85-a68b0ac8_jpg.rf.1e1a6f232fd461af6ef59f57a0a2d848.txt\n",
            "      ğŸ“„ bf3ce441-1f58c6c7_jpg.rf.59cc72c6f3991fe815b57092225882c2.txt\n",
            "      ğŸ“„ b83e94b9-fc9ee1c7_jpg.rf.7a3c6096a4ff12e6b4eb1f2ba07084ab.txt\n",
            "      ... and 2003 more files\n",
            "  ğŸ“ train/\n",
            "    ğŸ“ images/\n",
            "      ğŸ“„ b88a00df-e8484d02_jpg.rf.6ab9d8b93302e65a46172baeba478fd0.jpg\n",
            "      ğŸ“„ c6ef5bc4-96451c0f_jpg.rf.e0851e2acfb0144d393188ede4dee351.jpg\n",
            "      ğŸ“„ be9ce27e-65ec1c4e_jpg.rf.67bf9e8ec5f8396ee3d673b5fa63d14a.jpg\n",
            "      ğŸ“„ b5296e2a-25ab57d6_jpg.rf.fd016fa9b8dff25eb389c17bd8fe62ad.jpg\n",
            "      ğŸ“„ b24702e3-900f61ea_jpg.rf.b7be6719d0098844c8e5683ce8e5a5b0.jpg\n",
            "      ... and 7886 more files\n",
            "    ğŸ“ labels/\n",
            "      ğŸ“„ bb9d4d12-6cc166e9_jpg.rf.cd0ee48549125a33b8544b74ee40f279.txt\n",
            "      ğŸ“„ b6bb7bc8-795f455a_jpg.rf.95ccf1a061c43b1b78a9e3cdf82ded5f.txt\n",
            "      ğŸ“„ c55dde26-9a4d91e4_jpg.rf.d158b0982d86db2969a9da77c9e3b228.txt\n",
            "      ğŸ“„ b6decb24-390c9ae7_jpg.rf.fffd7532467d84a9d4ac43f24179e544.txt\n",
            "      ğŸ“„ c2bd70f5-d811bd56_jpg.rf.513f717a8cc1ac096f06b53644ee706f.txt\n",
            "      ... and 6649 more files\n",
            "\n",
            "âœ“ Found config file: /content/bdd100k/data.yaml\n",
            "\n",
            "Config contents:\n",
            "names:\n",
            "- car\n",
            "- pedestrian\n",
            "- traffic light\n",
            "- traffic sign\n",
            "nc: 4\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: bdd100k-3zgda\n",
            "  url: https://universe.roboflow.com/pedro-azevedo-3c9ol/bdd100k-3zgda/dataset/5\n",
            "  version: 5\n",
            "  workspace: pedro-azevedo-3c9ol\n",
            "test: ../test/images\n",
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "\n",
            "ğŸ“Š Dataset Statistics:\n",
            "  Training images: 7891\n",
            "  Validation images: 2008\n",
            "  Total: 9899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“¥ Cloning YOLOv9 repository...\")\n",
        "!git clone https://github.com/WongKinYiu/yolov9.git\n",
        "%cd yolov9\n",
        "\n",
        "# Install requirements\n",
        "print(\"\\nğŸ“¦ Installing requirements...\")\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# Download pre-trained weights\n",
        "print(\"\\nâ¬‡ï¸  Downloading pre-trained weights...\")\n",
        "!wget -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
        "\n",
        "if os.path.exists('yolov9-c.pt'):\n",
        "    print(\"âœ“ Pre-trained weights downloaded: yolov9-c.pt\")\n",
        "else:\n",
        "    print(\"âš ï¸  Failed to download weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-1jg_eUmxKq",
        "outputId": "2cab05df-9342-4e69-edea-52f71d55393e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¥ Cloning YOLOv9 repository...\n",
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 781, done.\u001b[K\n",
            "remote: Total 781 (delta 0), reused 0 (delta 0), pack-reused 781 (from 1)\u001b[K\n",
            "Receiving objects: 100% (781/781), 3.27 MiB | 3.56 MiB/s, done.\n",
            "Resolving deltas: 100% (330/330), done.\n",
            "/content/yolov9\n",
            "\n",
            "ğŸ“¦ Installing requirements...\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "â¬‡ï¸  Downloading pre-trained weights...\n",
            "âœ“ Pre-trained weights downloaded: yolov9-c.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if yaml_path and os.path.exists('yolov9-c.pt'):\n",
        "    print(\"\\nâœ… Everything is ready!\")\n",
        "    print(\"\\nğŸ“ Training command:\")\n",
        "    print(f\"python train.py --batch 16 --epochs 100 --img 640 --data {yaml_path} --weights yolov9-c.pt --device 0 --name bdd100k_pedestrian_vehicle\")\n",
        "\n",
        "    print(\"\\nğŸ’¡ Tips:\")\n",
        "    print(\"  â€¢ Adjust --batch based on GPU memory (16/8/4)\")\n",
        "    print(\"  â€¢ Increase --img to 1280 for better accuracy\")\n",
        "    print(\"  â€¢ Use --epochs 50 for quick testing\")\n",
        "    print(\"  â€¢ Monitor training with TensorBoard\")\n",
        "\n",
        "    print(\"\\nğŸ¯ For distance estimation, we'll add that after training!\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nâš ï¸  Setup incomplete. Please check the errors above.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH2ZF2dXm_gZ",
        "outputId": "ae2e100d-1559-4eb7-b61e-df4ad9cc7004"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Everything is ready!\n",
            "\n",
            "ğŸ“ Training command:\n",
            "python train.py --batch 16 --epochs 100 --img 640 --data /content/bdd100k/data.yaml --weights yolov9-c.pt --device 0 --name bdd100k_pedestrian_vehicle\n",
            "\n",
            "ğŸ’¡ Tips:\n",
            "  â€¢ Adjust --batch based on GPU memory (16/8/4)\n",
            "  â€¢ Increase --img to 1280 for better accuracy\n",
            "  â€¢ Use --epochs 50 for quick testing\n",
            "  â€¢ Monitor training with TensorBoard\n",
            "\n",
            "ğŸ¯ For distance estimation, we'll add that after training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov9\n",
        "\n",
        "# Use ultralytics YOLO instead (simpler, more reliable)\n",
        "!pip install -q ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pretrained model\n",
        "model = YOLO('yolov9c.pt')\n",
        "\n",
        "# Train\n",
        "results = model.train(\n",
        "    data='/content/bdd100k/data.yaml',\n",
        "    epochs=30,\n",
        "    imgsz=416,\n",
        "    batch=16,\n",
        "    device=0,\n",
        "    project='runs/train',\n",
        "    name='bdd10k_fast',\n",
        "    cache=True,\n",
        "    patience=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJRpLGsen5lW",
        "outputId": "f6bed496-af38-479c-9cef-e7ff454b8640"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9c.pt to 'yolov9c.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 49.4MB 22.3MB/s 2.2s\n",
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/bdd100k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9c.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=bdd10k_fast, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolov9/runs/train/bdd10k_fast, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 151.7MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n",
            "  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
            "  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n",
            "  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
            "  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
            "  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
            "  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n",
            " 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n",
            " 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
            " 22        [15, 18, 21]  1   5585884  ultralytics.nn.modules.head.Detect           [4, [256, 512, 512]]          \n",
            "YOLOv9c summary: 358 layers, 25,532,316 parameters, 25,532,300 gradients, 103.7 GFLOPs\n",
            "\n",
            "Transferred 931/937 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 188.3MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1613.4Â±380.4 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/bdd100k/train/labels... 6654 images, 1237 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7891/7891 2.3Kit/s 3.4s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/bdd100k/train/labels.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (3.8GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7891/7891 370.1it/s 21.3s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 579.4Â±230.6 MB/s, size: 44.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/bdd100k/valid/labels... 2008 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2008/2008 870.0it/s 2.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/bdd100k/valid/labels.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.0GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2008/2008 345.0it/s 5.8s\n",
            "Plotting labels to /content/yolov9/runs/train/bdd10k_fast/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias(decay=0.0)\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolov9/runs/train/bdd10k_fast\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      4.81G      1.459      1.238      1.102         29        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.5it/s 3:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.9it/s 21.5s\n",
            "                   all       2008      36289       0.45      0.311      0.302      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      5.56G      1.537      1.165      1.137         36        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.6it/s 3:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.9s\n",
            "                   all       2008      36289      0.439       0.31      0.294      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      5.63G      1.526      1.141      1.124         78        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.9s\n",
            "                   all       2008      36289      0.479      0.345      0.338      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      5.73G      1.486      1.101      1.107         25        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 21.0s\n",
            "                   all       2008      36289      0.511      0.365      0.362      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      5.78G      1.437      1.049      1.087         61        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.9s\n",
            "                   all       2008      36289      0.524      0.383      0.386      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      5.88G      1.397      1.008      1.072         28        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.7s\n",
            "                   all       2008      36289      0.551      0.381        0.4      0.195\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      5.93G       1.37     0.9851      1.059         80        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.9s\n",
            "                   all       2008      36289      0.548      0.398      0.408      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      6.03G      1.354      0.983      1.053        101        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.6s\n",
            "                   all       2008      36289      0.565      0.399      0.408      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      6.36G      1.327     0.9628      1.044        116        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.6s\n",
            "                   all       2008      36289      0.572      0.419      0.432       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      6.46G      1.321     0.9387      1.039         21        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.7s\n",
            "                   all       2008      36289      0.579      0.417      0.432      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30       6.7G      1.296     0.9173       1.03         87        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.4s\n",
            "                   all       2008      36289      0.591      0.434      0.453      0.223\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30       6.8G      1.285     0.9067      1.022        103        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.7s\n",
            "                   all       2008      36289      0.607      0.436      0.464      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      6.85G      1.273      0.902      1.021         85        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.4s\n",
            "                   all       2008      36289      0.601      0.438      0.465      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      6.96G      1.259     0.8955      1.014         29        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.6s\n",
            "                   all       2008      36289      0.603      0.447       0.47      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30         7G      1.239      0.873       1.01         80        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.3s\n",
            "                   all       2008      36289      0.615      0.451      0.481      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30       7.1G      1.238     0.8703      1.006         56        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.8s\n",
            "                   all       2008      36289      0.626      0.453      0.487      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      7.14G      1.228     0.8594      1.004         54        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.6s\n",
            "                   all       2008      36289      0.629      0.458      0.491      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      7.33G      1.206     0.8411     0.9965         45        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.4s\n",
            "                   all       2008      36289      0.626      0.462      0.492      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      5.13G      1.205     0.8408     0.9944         54        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.5s\n",
            "                   all       2008      36289      0.634      0.462      0.499      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      5.13G      1.199     0.8301     0.9916         73        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.6s\n",
            "                   all       2008      36289      0.639      0.463      0.503      0.255\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      5.51G      1.235     0.8365      0.992         55        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.8s\n",
            "                   all       2008      36289      0.631       0.47      0.503      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      5.51G      1.223     0.8249     0.9871         49        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.7s\n",
            "                   all       2008      36289      0.633      0.468        0.5      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      5.51G      1.213     0.8127     0.9831         47        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.7s\n",
            "                   all       2008      36289      0.634      0.475       0.51       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      5.58G      1.204     0.8031     0.9788         41        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.6s\n",
            "                   all       2008      36289      0.653      0.477      0.517      0.263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      5.91G      1.193     0.7946     0.9761         50        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.6s\n",
            "                   all       2008      36289      0.641      0.489      0.521      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      6.02G      1.186      0.784     0.9735         51        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.7s\n",
            "                   all       2008      36289      0.644      0.485       0.52      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      6.06G       1.18     0.7777     0.9681         19        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.4s\n",
            "                   all       2008      36289       0.65      0.489      0.526      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      6.16G      1.168     0.7699     0.9645         75        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.0it/s 20.7s\n",
            "                   all       2008      36289      0.649      0.493      0.529      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      6.21G      1.159      0.763      0.963         26        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.4s\n",
            "                   all       2008      36289      0.661       0.49      0.533      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      6.31G      1.157     0.7608     0.9628         35        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 494/494 2.7it/s 3:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.5s\n",
            "                   all       2008      36289      0.664      0.494      0.536      0.276\n",
            "\n",
            "30 epochs completed in 1.820 hours.\n",
            "Optimizer stripped from /content/yolov9/runs/train/bdd10k_fast/weights/last.pt, 51.6MB\n",
            "Optimizer stripped from /content/yolov9/runs/train/bdd10k_fast/weights/best.pt, 51.6MB\n",
            "\n",
            "Validating /content/yolov9/runs/train/bdd10k_fast/weights/best.pt...\n",
            "Ultralytics 8.3.214 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv9c summary (fused): 156 layers, 25,322,332 parameters, 0 gradients, 102.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.8it/s 22.4s\n",
            "                   all       2008      36289      0.663      0.494      0.537      0.276\n",
            "                   car       1987      20806      0.732      0.672      0.721      0.459\n",
            "            pedestrian        663       2880      0.571      0.433      0.461      0.213\n",
            "         traffic light       1130       5480       0.67      0.381      0.426      0.152\n",
            "          traffic sign       1643       7123      0.681      0.489      0.538       0.28\n",
            "Speed: 0.1ms preprocess, 6.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolov9/runs/train/bdd10k_fast\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVEd_m8mp1sD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}